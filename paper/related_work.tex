\section{Related Work}
Related work for our contribution stems from three areas of research: deformable object manipulation (in particular knot-tieing), learning from demonstrations, \dhm{and a third thing}

\subsection{Learning from Demonstrations}
The problem of learning from demonstrations deals with the generalization of expert demonstrations to new scenarios. 
This is a broad area of research with many different approaches and broad applicabilty.\dhm{Cite Veloso survey and Schaal paper}
The approach to learning from demonstrations applied here is most closely linked to behavioral cloning; where an agent atempts to learn a function that directly maps states to actions so as to mimic the experts behavior. 

One of the first successfull applications of this strategy was the ALVINN system, which utilized a neural network to learning a policy such that an autonomous car could follow a road\dhm{CITE}.
In this a function is learned that can map image input and range finder input to left and right steering commands. 
This research direction has been furthered recently by Lecun et al. \dhm{CITE} who use a convolutional network to learn a steering policy for off-road driving.
Bagnell et al. propose a method to directly control a Micro UAV from RGB camera input and describe a method to account for differences in the training distribution under expert demonstration and the induced distribution under a learned policy\dhm{CITE}. 
These approaches differ from the proposed method in that they do learning for low-dimensional action spaces and directly imitate the expert.
In contrast, MMQL copes with high dimensional state and action spaces as well as accounting for temporal constraints from demonstrated behavior.

Miyamoto et al. \dhm{CITE} describe an approach for learning to play Kendama and hit a tennis ball from demonstrated actions. 
This method was successful at generalizing a human trajectory to a robot and incorporates the sequential combination of multiple demonstrations.
However, their approach requires a hand tuning of waypoints and does not generalize to new scenes.


The most similar behavioral cloning working to our approach is that of Isaac et al.~\dhm{CITE}. 
They use behavioral cloning to learn to fly an airplane.
They make use of an abstract goal directed layer, which sits on top of a low-level PID controller.
This goal directed learning is similar in spirit to ours, although it makes use of a different formalism.
The primary difference with this work is in the complexity of the low level controllers and complexity derived from manipulation.

Similarly to our approach, \citet{Dvijotham_ICML2010} also attempt to directly
learn a value function or Q-function for a MDP given sample transitions
generated by an optimal control policy. However, they assume either a discrete
state space or a linear dynamics model. In contrast, our method makes no
assumptions about the size of the state space or the dynamics model, instead
relying on segments of expert demonstrations as a means of navigating the state
space efficiently. \et{Someone who actually understands robotics should probably
  check this statement.}

\subsection{Deformable Object Manipulation}
Our approach can be applied towards a variety of tasks in robotics,
including the manipulation of deformable objects.
In particular, we demonstrate the effectiveness of our approach for
knot tying, a commonly studied manipulation task in robotics.
Previous approaches to knot tying usually depend on rope-specific knowledge
and assumptions.
For instance, in knot planning from observation (KPO), knot theory is used
to recognize rope configurations and define movement primitives in visual
observations of humans tying knots \cite{Morita_ICRA2003, Takamatsu_TransRob2006}.
Existing motion planning approaches for knot tying use topological
representations of rope states (i.e. sequences of rope crossings and their
properties) and define a model for transitioning between topological states
\cite{Saha_ExpRobotics2008, Wakamatsu_IJRR2006}.
Robust open loop execution of knot tying has also been explored \cite{Bell_PhD2010}.
