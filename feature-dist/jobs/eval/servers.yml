# The file containing expert examples.
datafile: jobs/eval/holdout_set.h5

# Output from each remote machine will be collected into this folder.
outfolder: jobs/eval/out

# The output file to create.
outfile: jobs/eval/nearest_neighbor_result.h5

# This will be created if it doesn't exist. Used to store splits that are distributed to machines,
# where a "split" is the subset of examples that a particular core runs on.
splitsdir: jobs/eval/splits

# This is the folder containing the scripts that will run on remote machines.
payload:
  path: jobs/eval/payload
  additional-files:  # include additional files in the payload that aren't in the payload folder
    - path: ../data/all.h5  # path to file on disk
      archive-name: data/all.h5  # path inside the payload archive

# For each server, specify host (the hostname), path (the directory to use on the remote, which
# will be created if necessary), and cores (the number of cores to run with).
servers:
  - host: rll5.eecs.berkeley.edu
    path: comp/eval
    cores: 4

  - host: rll7.eecs.berkeley.edu
    path: comp/eval
    cores: 4

  - host: primus.banatao.berkeley.edu
    path: comp/eval
    cores: 4
